{
    "loss": "softmax_cross_entropy_with_logits",
    "optimizers": "Adam",
    "lr": {
        "learning_rate": 0.001,
        "clipvalue": 0.001
    },
    "metric": "Accuracy",
    "seed": 42,
    "epochs": 800,
    "clip_epochs": [
        0,
        60
    ],
    "config_type": "trainer",
    "config_class": "BaseTrainerConfig"
}