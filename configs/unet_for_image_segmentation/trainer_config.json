{
    "loss": "softmax_cross_entropy_with_logits",
    "optimizers": "Adam",
    "lr": {
        "learning_rate": 0.001
    },
    "metric": null,
    "seed": 42,
    "epochs": 25,
    "clip_epochs": null,
    "config_type": "trainer",
    "config_class": "BaseTrainerConfig"
}